{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer_Learning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWp-u-Y8N-nY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9d1fed9-6f30-41e6-da2e-c222ad7ac3b0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUAsQAah-ThK"
      },
      "source": [
        "# import the necessary packages\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator #augmentation technique : creating more variety when u dont have enough 4 training by adding random features like noise, brightness\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHbJyycmGGba"
      },
      "source": [
        "INIT_LR = 1e-3  # =0.0001\n",
        "EPOCHS = 200\n",
        "BS = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] loading images...\")\n",
        "imagePaths = list(paths.list_images(\"/content/drive/MyDrive/Cars/dataset\")) #list containing path of every image\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "for imagePath in imagePaths:\n",
        "\tlabel = imagePath.split(os.path.sep)[-2]\n",
        "\timage = cv2.imread(imagePath)\n",
        "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) #open cv usually loads in bgr hence conversion to rgb\n",
        "\timage = cv2.resize(image, (224, 224))\n",
        "\n",
        "\tdata.append(image)\n",
        "\tlabels.append(label)\n",
        "\n",
        "data = np.array(data) / 255.0\n",
        "labels = np.array(labels)"
      ],
      "metadata": {
        "id": "Lx48hNrvICqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aeEFrUb-VBZ"
      },
      "source": [
        "\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        "labels = to_categorical(labels)\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
        "\ttest_size=0.20, stratify=labels, random_state=42) #stratified splitting within the class for equal training\n",
        "\n",
        "trainAug = ImageDataGenerator(rotation_range=10,\n",
        "                                  width_shift_range=0.1,\n",
        "                                  height_shift_range=0.1,\n",
        "                                  shear_range=0.1, #shear : change in perception of image\n",
        "                                  brightness_range=(0.3, 1.0),\n",
        "                                  horizontal_flip=True,\n",
        "                                  vertical_flip=True,\n",
        "                                  fill_mode='nearest') #zoomin/out using nearest neighbor approach"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ways To Train The Model\n",
        "\n",
        "*1) vgg, pretrained model , TL\n",
        "\n",
        "2) Vgg, change last layer alone with number of classes (ly)\n",
        "\n",
        "3) vgg, ly + pretrained weights\n",
        "\n",
        "*4) vgg, ly, partial unfreeze layer by layer to update weights"
      ],
      "metadata": {
        "id": "fmsDcy2CbWqX"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KByhBSjf-lHh"
      },
      "source": [
        "# method 3\n",
        "baseModel = VGG16(weights=\"imagenet\", include_top=False,\n",
        "\tinput_tensor=Input(shape=(224, 224, 3))) #pretrained\n",
        "\n",
        "\n",
        "headModel = baseModel.output #now training\n",
        "headModel = AveragePooling2D(pool_size=(2, 2))(headModel)\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "headModel = Dense(64, activation=\"relu\")(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(2, activation=\"sigmoid\")(headModel)\n",
        "\n",
        "\n",
        "model = Model(inputs=baseModel.input, outputs=headModel)\n",
        "\n",
        "for layer in baseModel.layers:\n",
        "\tlayer.trainable = False #freeze base model alone to ensure no weight updation happens during back propagation since base model is aldready trained\n",
        "\n",
        "\n",
        "print(\"[INFO] compiling model...\")\n",
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "\n",
        "print(\"[INFO] training head...\")\n",
        "H = model.fit_generator(\n",
        "\ttrainAug.flow(trainX, trainY, batch_size=BS),\n",
        "\tsteps_per_epoch=len(trainX) // BS,\n",
        "\tvalidation_data=(testX, testY),\n",
        "\tvalidation_steps=len(testX) // BS,\n",
        "\tepochs=EPOCHS)\n",
        "\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZu_2K1S-sPD"
      },
      "source": [
        "print(H.history.keys())\n",
        "\n",
        "# Loss Curves\n",
        "plt.figure(figsize=(25, 10))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(H.history['loss'],'-g',linewidth=1.0)\n",
        "plt.legend(['Training loss', 'Validation Loss'],fontsize=14)\n",
        "plt.xlabel('Epochs ',fontsize=16)\n",
        "plt.ylabel('Loss',fontsize=16)\n",
        "plt.title('Loss Curves',fontsize=22)\n",
        "\n",
        "# Accuracy Curves\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(H.history['accuracy'],'-g',linewidth=1.0)\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=14)\n",
        "plt.xlabel('Epochs ',fontsize=16)\n",
        "\n",
        "plt.ylabel('Accuracy',fontsize=16)\n",
        "plt.title('Accuracy Curves',fontsize=22)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}